# -*- coding: utf-8 -*-
"""LaneDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AECuvj0lndAPY72bukF08FWc1p-GCHT7

# Lane Detection
"""

from google.colab import drive
drive.mount('/content/drive')

# Clone repository into /content directory
!git clone https://github.com/Dat0309/Road-Lane-line-Detect.git

# If you want to clone it into your Google Drive, specify the path
# Replace '/content/drive/MyDrive/' with the desired path in your Google Drive
!git clone https://github.com/Dat0309/Road-Lane-line-Detect.git 'https://drive.google.com/drive/folders/1tfLFeNMamRMruA-dfW9Ln4xN5Lg7J3RQ'

import os

# Navigate to the cloned repository directory
os.chdir("https://drive.google.com/drive/folders/1tfLFeNMamRMruA-dfW9Ln4xN5Lg7J3RQ")

# List the contents of the directory
!ls

!ls

# Example: Read the contents of a file
with open("lanes.py", "r") as file:
    contents = file.read()
    print(contents)

# Example: Run a Python script
!python lanes.py

!python training.py

import matplotlib
matplotlib.use('Agg')
import cv2

# Check if test_img is defined in lanes.py
with open("lanes.py", "r") as file:
    contents = file.read()
    if "test_img" in contents:
        # Import the variable from lanes.py
        from lanes import test_img

# Print the current working directory
!pwd

# Print the list of files in the directory
!ls

import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt
from numpy.lib.type_check import imag

def canny(image):
    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    blur = cv.GaussianBlur(gray, (5, 5), 0)
    canny = cv.Canny(blur, 50, 150)
    return canny

def region_of_interest(image):
    #get height of image
    height = image.shape[0]
    poligon = np.array([[(200, height), (1100, height), (550, 250)]])
    mask = np.zeros_like(image)
    #fill mask in poligon with color white
    cv.fillPoly(mask, poligon, 255)
    # Thực hiện phép "and" hai mảng nhị phân của hai hình ảnh để lọc ra viền của poligon
    mask_image = cv.bitwise_and(image, mask)
    return mask_image

def display_lines(image, lines):
    line_image = np.zeros_like(image)
    if lines is not None:
        for x1, y1, x2, y2 in lines:
            cv.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 10)
    return line_image

def average_slope_intercept(image, lines):
    left_fir= []
    right_fit = []
    for line in lines:
        x1, y1, x2, y2 = line.reshape(4)
        parameters = np.polyfit((x1, x2), (y1, y2), 1)
        slope = parameters[0]
        intercept = parameters[1]
        if slope < 0:
            left_fir.append((slope, intercept))
        else:
            right_fit.append((slope, intercept))

    lef_fit_average = np.average(left_fir, axis=0)
    right_fit_average = np.average(right_fit, axis= 0)
    left_line = make_coordinates(image, lef_fit_average)
    right_line = make_coordinates(image, right_fit_average)
    return np.array([left_line, right_line])

def make_coordinates(image, line_parameters):
    slope, intercept = line_parameters
    y1 = image.shape[0]
    y2 = int(y1*(3/5))
    x1 = int((y1 - intercept)/ slope)
    x2 = int((y2 - intercept)/ slope)
    return np.array([x1, y1, x2, y2])

import cv2
from google.colab.patches import cv2_imshow

cap = cv2.VideoCapture('test2.mp4')
while(cap.isOpened()):
    ret, frame = cap.read()
    canny_img =  canny(frame)
    lines = cv2.HoughLinesP(region_of_interest(canny_img), 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)
    averaged_lines = average_slope_intercept(frame, lines)
    line_image = display_lines(frame, averaged_lines)

    combo_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)

    cv2_imshow(combo_image)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

"""# Reading dashboard Feed Video"""

import cv2

# Set a counter to track the number of images processed
image_count = 0

cap = cv2.VideoCapture('test2.mp4')
while(cap.isOpened()):
    ret, frame = cap.read()
    if not ret:
        break

    # Check if the desired number of images have been processed
    if image_count >= 100:
        break

    # Process the current image (canny_img, lines, etc.)
    # ... (your existing code here) ...

    image_count += 1

cap.release()
cv2.destroyAllWindows()

from functools import cache
import matplotlib.pyplot as plt
import numpy as np
import cv2 as cv
import os
import matplotlib.image as mpimg
from numpy.core.fromnumeric import mean
import math

def interested_region(img, vertices):
    if len(img.shape) >2:
        mask_color_ignore = (255,) * img.shape[2]
    else:
        mask_color_ignore = 255

    cv.fillPoly(np.zeros_like(img), vertices, mask_color_ignore)
    return cv.bitwise_and(img, np.zeros_like(img))

def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):
    lines = cv.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)
    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)
    lines_draw(line_img, lines)
    return line_img

def lines_draw(img, lines, color = [255,0,0], thickness=6):
    global cache
    global first_frame
    slope_l, slope_r = [],[]
    lane_l, lane_r = [],[]

    α =0.2

    for line in lines:
        for x1, y1, x2, y2 in line:
            slope = (y2-y1) / (x2-x1)
            if slope > 0.4:
                slope_r.append(slope)
                lane_r.append(line)
            elif slope < -0.4:
                slope_l.append(slope)
                lane_l.append(line)
        img.shape[0] = min(y1, y2, img.shape[0])
    if((len(lane_l) == 0) or (len(lane_r) == 0)):
        print('no Road Lane Line detected')
        return 1
    slope_mean_l = np.mean(slope_l, axis= 0)
    slope_mean_r = np.mean(slope_r, axis= 0)
    mean_l = np.mean(np.array(lane_l), axis= 0)
    mean_r = np.mean(np.array(lane_r), axis= 0)

    if ((slope_mean_r == 0) or (slope_mean_l == 0)):
        print('diving in road is zero')
        return 1

    x1_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0])) / slope_mean_l)
    x2_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0])) / slope_mean_l)
    x1_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0])) / slope_mean_r)
    x2_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0])) / slope_mean_r)

    if x1_l > x1_r:
        x1_l = int((x1_l + x1_r) / 2)
        x1_r = x1_l
        y1_l = int((slope_mean_l * x1_l) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))
        y1_r = int((slope_mean_r * x1_r) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))
        y2_l = int((slope_mean_l * x2_l) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))
        y2_r = int((slope_mean_r * x2_r) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))
    else:
        y1_l = img.shape[0]
        y2_l = img.shape[0]
        y1_r = img.shape[0]
        y2_r = img.shape[0]

    present_frame = np.array([x1_l, y1_l, x2_l, y2_l, x1_r, y1_r, x2_r, y2_r], dtype="float32")

    if first_frame == 1:
        next_frame = present_frame
        first_frame = 0
    else:
        prev_frame = cache
        next_frame = (1-α) * prev_frame + α*present_frame

    cv.line(img, (int(next_frame[0]), int(next_frame[1])), (int(next_frame[2]),int(next_frame[3])), color, thickness)
    cv.line(img, (int(next_frame[4]), int(next_frame[5])), (int(next_frame[6]),int(next_frame[7])), color, thickness)

    cache = next_frame

# #process each frame of video to detect lane
def weihted_img(img, initial_img, a = 0.8, b = 1., c = 0.):
    return cv.addWeighted(initial_img, a, img, b, c)

from google.colab.patches import cv2_imshow
def process_image(image):
    global first_frame

    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    img_hsv = cv.cvtColor(image, cv.COLOR_RGB2HSV)

    lower_yellow = np.array([20, 100, 100], dtype="uint8")
    upper_yellow = np.array([30, 255, 255], dtype="uint8")

    mask_yellow = cv.inRange(img_hsv, lower_yellow, upper_yellow)
    mask_white = cv.inRange(gray_image, 200, 255)
    mask_yw = cv.bitwise_or(mask_white, mask_yellow)
    mask_yw_image = cv.bitwise_and(gray_image, mask_yw)

    gauss_gray = cv.GaussianBlur(mask_yw_image, (5, 5), 0)
    canny_edges = cv.Canny(gauss_gray, 50, 150)

    imshape = image.shape
    lower_left = [imshape[1]/9, imshape[0]]
    lower_right = [imshape[1] - imshape[1]/9, imshape[0]]
    top_left = [imshape[1]/2 - imshape[1]/8, imshape[0]/2 + imshape[0] / 10]
    top_right = [imshape[1]/2 + imshape[1]/8, imshape[0]/2 + imshape[0]/10]
    vertices = [np.array([lower_left,top_left,top_right,lower_right],dtype=np.int32)]
    roi_image = interested_region(canny_edges, vertices)

    theta = np.pi/180

    line_image = hough_lines(roi_image, 4, theta, 30, 100, 180)
    result = weihted_img(line_image, image, a=0.8, b=1., c=0.)
    return result

cap = cv.VideoCapture('test2.mp4')
while (cap.isOpened()):
    ret, frame = cap.read()

    cv2_imshow(frame)  # Use cv2_imshow() instead of cv2.imshow()

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

!git clone https://github.com/Umeshmanchikanti/Road_Lane_Detection.git

# Commented out IPython magic to ensure Python compatibility.
# %cd Road_Lane_Detection

!cp /content/Road_Lane_Detection/*

!git add .

